# OpenAI Moderation

OpenAI Moderation 노드는 OpenAI의 콘텐츠 모더레이션 API를 호출하여 입력된 문장의 정책 위반 여부를 자동으로 검사하는 기능을 제공합니다. 사용자의 입력값이 민감하거나 부적절할 수 있는 경우, 사전 필터링을 위한 전처리 용도로 활용됩니다.

***

### 주요 기능

* OpenAI의 정책 위반 여부를 자동 감지
* 입력값이 위험 또는 부적절한 경우 사용자 정의 메시지 반환
* Agent 또는 LLM 실행 전에 필터링 단계로 활용 가능
* 다양한 자동화 시나리오에 콘텐츠 안전성 확보 수단으로 적용

<figure><img src="../../../.gitbook/assets/스크린샷 2025-05-19 175820.png" alt=""><figcaption><p>WindyFlo OpenAI Moderation</p></figcaption></figure>

### 입력값 (Inputs)

| 항목                 | 설명                                   | 필수 여부 |
| ------------------ | ------------------------------------ | ----- |
| Connect Credential | OpenAI API 인증 정보 (Credential에 등록 필요) | 필수    |

***

### 파라미터 (Parameters)

| 항목            | 설명                                                                                                      |
| ------------- | ------------------------------------------------------------------------------------------------------- |
| Error Message | 정책 위반 시 사용자에게 반환할 커스텀 메시지 (예: `"Cannot Process! Input violates OpenAI’s content moderation policies."`) |

***

### 출력값 (Outputs)

| 출력 항목      | 설명                           |
| ---------- | ---------------------------- |
| Moderation | 모더레이션 결과 객체 (위반 여부, 범주 등 포함) |

***

### 활용 예시

* 챗봇 또는 에이전트에서 사용자 입력을 사전 검열하여 부적절 발화 차단
* LLM 응답 전처리 또는 후처리 흐름에 안전성 보장을 위한 모듈로 삽입
* 사용자 생성 콘텐츠(UGC) 업로드 시 자동 필터링 로직 구성
* 비속어나 민감 정보 포함 여부 검출이 필요한 고객 서비스 시나리오

***

### 사용 팁

* Error Message는 사용자 친화적 문구로 설정하여 UX 품질을 향상시킬 수 있습니다.
* 토큰 비용을 절감하기 위해 Moderation 노드는 LLM 호출 전에 사용하는 것이 효율적입니다.
* 정책 위반 여부를 기준으로 IfElseFunction과 연계하여 흐름 제어도 가능합니다.

***

### 주의사항

* Connect Credential이 누락되면 API 호출이 불가능하며 오류가 발생합니다.
* OpenAI의 정책 범주는 `hate`, `self-harm`, `sexual`, `violence` 등이며, 민감도는 다소 높을 수 있습니다.
* 해당 노드는 입력을 필터링할 뿐, 출력 내용을 검열하는 기능은 제공하지 않습니다.
* Output 결과는 JSON 객체 형태이며, 후속 노드에서 직접 파싱하거나 조건 분기 노드와 연동해야 합니다.
